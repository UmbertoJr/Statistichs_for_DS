{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Homework 1\"\nauthor: \"Umberto Junior Mele 1388371\"\ndate: \"13 marzo 2017\"\noutput: pdf_document\n---\n\n\na)\n\n$Y_i$ is a random variable with distribution $Bernoulli$ and $i.i.d.$ so we can write down the joint distribution, like this:\n\n$$Pr(Y_{1}=y_1,......, Y_{100}= y_{100} |\\theta) = \\prod_{i=1}^{100} \\theta^{y_i}(1 -\\theta)^{1-y_i}= L(\\theta)$$\nwhere $L(\\theta)$ is the Likelihood function.\n\nWhile the probability distribution of $Pr(\\sum_{i=1}^{100} Y_i = y |\\theta)$\nis defined by the random variable $Z=Y_1 + .... + Y_{100}$, that is distribuited like a Binomial distribution, so:\n$$Pr(\\sum_{i=1}^{100} Y_i = y |\\theta) = Pr(Z=y) = \\binom{100}{y} \\theta^y (1 - \\theta)^{100-y} $$\n\n\n\n2)\n\n```{r}\ntheta <- seq(0,1,0.1)\nprob_Z.equal.57 <- dbinom(57 ,100, theta)\nplot(theta, prob_Z.equal.57, xlab = 'theta' , ylab = 'prob')\n```\n\n\n\n3)\nRemembering that the posterior distribution is:\n$$\\pi(\\theta | x) = \\frac{L(\\theta) \\cdot \\pi(\\theta)}{m(x)}$$\n\n```{r}\nprior <- function(t)  1/11 *(t < 1 & t >0)\nL <-  function(t) dbinom(57,100,t)\nm <- function(all.theta){\n  su <- 0\n  for(t in all.theta){\n    su <- su + prior(t)*L(t)\n  }\n  return(su)\n}\n\nposterior <- function(t) prior(t)*L(t)/m(theta)\nposterior <- Vectorize(posterior)\n\nplot(theta ,posterior(theta), ylab = 'posterior')\ncurve(posterior(x), add = T, col='blue')\n\n```\n\n```{r}\nprior <- function(t) dunif(t)*(t>0 & t<1 )\nL <-  function(t) dbinom(57,100,t)\njoint <- function(t) L(t)*prior(t)\nm <- integrate(joint,0,1)\n\nposterior <- function(t) prior(t)*L(t)/m$value\nposterior <- Vectorize(posterior)\n\ncurve(posterior, col = 'violet')\n\n\n```\n\n\ne)\nWe know that the posterior distribution is a $Beta(1+57, 1 +43)$ because if we use the Conjugate Analysis for this problem, so we use a $Beta$ distro as Prior:\n\n$$\\pi(\\theta | \\bar{Z}) = \\binom{100}{57} \\theta^{57} (1 - \\theta)^{100-57} \\cdot \\frac{\\theta^{\\alpha - 1}(1 - \\theta)^{\\beta - 1}}{\\beta(\\alpha,\\beta)} \\propto \\theta^{57 + \\alpha-1} (1 - \\theta )^{43 + \\beta -1}$$\n\nso the posterior distribution is a $Beta$ distribution with parameters $\\dot\\alpha = 57 + \\alpha$ and $\\dot\\beta = 43 + \\beta$, so the prior distribution is a $Beta(1,1)$ that is the same distribution of a $Unif(0,1)$.\n\n\n```{r}\ncurve(dbeta(x,1,1))\n```\n```{r}\nprior <- function(t) dbeta(t,1,1)*(t>0 & t<1 )\nL <-  function(t) dbinom(57,100,t)\njoint <- function(t) L(t)*prior(t)\nm <- integrate(joint,0,1)\n\nposterior_3 <- function(t) prior(t)*L(t)/m$value\nposterior_3 <- Vectorize(posterior_3)\n\ncurve(posterior_3, col = 'green')\n\n```\n\n\n\n\n\n2)\na)\n\nThe prior predictive distribution is defined by:\n$$m(\\cdot) = \\int f(\\cdot | \\theta) \\pi(\\theta) d\\theta = \\int \\frac{\\sqrt{\\lambda}}{\\sqrt{2\\pi}}e^{- \\frac{\\lambda(x - \\theta)^2}{2}} \\cdot \\frac{\\sqrt{\\nu}}{\\sqrt{2\\pi}}e^{- \\frac{\\nu(\\theta - \\mu)^2}{2}} d\\theta $$\n$$ \\propto  \\int e^{-\\frac{\\lambda(x^2- 2 \\theta x +\\theta^2)+ \\nu(\\theta^2 - 2\\theta \\mu + \\mu^2)}{2}}d\\theta \\quad \\propto e^{-\\frac{\\lambda x^2 + \\nu \\mu^2}{2}}\\int e^{-\\frac{(\\lambda + \\nu)\\theta^2}{2}+(\\lambda x +\\nu \\mu)\\theta}d\\theta $$\nNow remembering that:\n$$ N(\\mu=\\frac{b}{a} ; \\sigma^2=\\frac{1}{a}) \\propto exp\\{-\\frac{a x^2}{2} + bx\\}\n$$\nand..\n$$\\int \\frac{\\sqrt{a}}{\\sqrt{2\\pi}} \\cdot e^{-\\frac{ax^2}{2}+bx - \\frac{b^2}{2a}} dx = 1\n$$\nwe can compute:\n$$\\int e^{-\\frac{ax^2}{2}+ bx} = \\frac{\\sqrt{2\\pi}}{\\sqrt{a}} \\cdot e^{\\frac{b^2}{2a}}$$\nso:\n$$m(\\cdot) \\propto \\quad e^{-\\frac{\\lambda x^2 + \\nu \\mu^2}{2}}\\int e^{-\\frac{(\\lambda + \\nu)\\theta^2}{2}+(\\lambda x +\\nu \\mu)\\theta}d\\theta \\quad \\propto e^{-\\frac{\\lambda x^2 + \\nu \\mu^2}{2}} \\cdot e^{\\frac{(\\lambda x+ \\nu \\mu)^2}{2(\\lambda + \\nu)}}$$\n\n$$\\propto e^{-\\frac{\\lambda x^2}{2}} \\cdot e^{\\frac{\\lambda^2 x^2 + 2 \\lambda x \\nu \\mu}{2(\\lambda + \\nu)}} \\propto e^{-\\frac{1}{2}(\\lambda - \\frac{\\lambda^2}{\\lambda + \\nu})x^2 + \\frac{\\lambda\\nu\\mu}{\\lambda + \\nu}x}$$\nthe last function is a $N(a=(\\lambda - \\frac{\\lambda^2}{\\lambda + \\nu}) ; b =\\frac{\\lambda\\nu\\mu}{\\lambda + \\nu})$;\nso the prior predictive distribution is a normal: $N(\\frac{a}{b}= \\mu; \\frac{1}{a}=\\frac{\\lambda + \\nu}{\\lambda \\nu})$\n\n\nAnother way to compute this distribution is to think the distribution as a convolution:\n$$m(\\cdot) = \\int f(\\cdot | \\theta) \\pi(\\theta) d\\theta = \\int \\frac{\\sqrt{\\lambda}}{\\sqrt{2\\pi}}e^{- \\frac{\\lambda(x - \\theta)^2}{2}} \\cdot \\frac{\\sqrt{\\nu}}{\\sqrt{2\\pi}}e^{- \\frac{\\nu(\\theta - \\mu)^2}{2}} d\\theta = \\int W(x - \\theta)\\cdot \\pi(\\theta) d\\theta$$\nwhere $W(w)$ is a Normal $N(0;\\frac{1}{\\lambda})$.\n\nSo for the properties of convolution we know that:\n\n$$X = W + \\theta$$\nwhere $W$ and $\\theta$ must be independent and both Gaussians.\n\n$$ \\theta \\sim N(\\mu_{\\pi}, \\sigma_{\\pi}^2=\\frac{1}{\\nu_{\\mu}^2})$$\n\n$$W\\sim N(0,\\sigma^2=\\frac{1}{\\lambda})$$\n\n$$X \\sim N(0,\\lambda)\\ast N(\\mu, \\nu) \\sim N(\\mu, \\frac{\\lambda + \\nu}{\\lambda \\nu})$$)\n\nb)\nRemembering that:\n\n$$m(x_{new}|\\hat x) = \\int f(x_{new}| \\theta) \\pi(\\theta |\\hat  x) d\\theta$$\n\nwe know that $\\pi(\\theta | x)$ is the posterior distribution that is a $N(\\mu_{\\theta}^{'} , \\lambda_{\\theta}^{'} )$:\n$$ \\mu_{\\theta}^{'} = w \\cdot \\mu + (1 - w)\\cdot \\bar x_n$$\n\n$$ \\nu_{\\theta}^{'} = \\nu + N \\lambda$$\nand:\n\n$$w = \\frac{\\nu}{\\nu + N \\lambda}$$\n\nso it's easy now to compute the posterior predictive distribution:\n\n$$m(x_{new}|x) = \\int f(x_{new}| \\theta) \\pi(\\theta | x) d\\theta = \\int \\frac{\\sqrt{\\lambda}}{\\sqrt{2\\pi}}e^{- \\frac{\\lambda(x - \\theta)^2}{2}} \\cdot \\frac{\\sqrt{\\nu_{\\theta}^{'}}}{\\sqrt{2\\pi}}e^{- \\frac{\\nu_{\\theta}^{'}(\\theta - \\mu_{\\theta}^{'})^2}{2}} d\\theta$$\n$$\\propto e^{-\\frac{1}{2}(\\lambda - \\frac{1}{\\lambda + \\nu_{\\theta}^{'}})x^2 + \\frac{\\mu_{\\theta}^{'}}{\\lambda + \\nu_{\\theta}^{'}}x}$$\nbecause is the same integral we compute before.\n\nSo the posterior predictive distribution is a $N(a=(\\lambda - \\frac{1}{\\lambda + \\nu_{\\theta}^{'}}) ; b =\\frac{\\mu_{\\theta}^{'}}{\\lambda + \\nu_{\\theta}^{'}})$\n\n\n[//]: <> (using the same trick we did before:\n$$m(x_{new}|x) \\sim N(\\mu_{\\theta}^{'}, \\frac{\\lambda_{\\theta}^{'} + \\lambda}{\\lambda_{\\theta}^{'} \\cdot \\lambda})$$)\n\n\n\nc)\n\nWe want that $P_{\\pi}(-5 \\leq \\theta \\leq 5) = 0.96$, and $\\mu = 0$ so:\n\n$$P_{\\pi}(-5 \\leq \\theta \\leq 5) = P_{\\pi}(\\frac{-5 - \\mu}{\\sigma} \\leq\\frac{\\theta - \\mu}{\\sigma} \\leq \\frac{5 - \\mu}{\\sigma}) = P_{\\pi}(\\frac{-5}{\\sigma} \\leq\\ Z \\leq \\frac{5}{\\sigma})= \\Phi( \\frac{5}{\\sigma}) - \\Phi(- \\frac{5}{\\sigma})= 1 - 2\\Phi(-\\frac{5}{\\sigma})$$\n$$\\Phi(- \\frac{5}{\\sigma})=0.02$$\n\n```{r}\nqnorm(0.02)\n```\n\n$$\\sigma = \\frac{-5}{-2.053749}=2.4346$$\n\nso the prior is a $N(0,5.93)$.\n\n\n\nd)\n\nSo:\n$$\\pi(\\theta | \\bar X) \\propto L(\\theta) \\cdot \\pi(\\theta) $$\n\n```{r}\nX.bar <- c(-1.25, 8.77, 1.18, 10.66, 11.81, -6.09, 3.56, 10.85, 4.03, 2.13)\n\nL <- function(thet){\n  prod=1\n  for(x in X.bar){\n    prod = prod*dnorm(x, mean=thet, sd=sqrt(3))\n  }\n  return(prod)\n}\ncurve(L, xlab = 'theta', ylab = 'L(theta)', from = 0, to = 10)\n```\n```{r}\npr <- function(thet) dnorm(thet, 0, (-5/qnorm(0.02)))\npr <- Vectorize(pr)\n\ncurve(pr, ylab = 'prior', xlab='theta', from = -10, to = 10)\n```\n\n```{r}\njnt <- function(t) L(t)*pr(t)\nm.x_bar <- integrate(jnt, -Inf, Inf)\npost <- function(t) jnt(t)/m.x_bar$value\ncurve(post, from = 0, to = 10)\n\n```\n\n",
    "created" : 1489398865793.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "730809370",
    "id" : "2FAB6DE2",
    "lastKnownWriteTime" : 1489617184,
    "last_content_update" : 1489617184674,
    "path" : "C:/Users/Umbertojunior/Desktop/data science/Second Semestr/SDS 2/hw 1/primo homework/homework_1.Rmd",
    "project_path" : "homework_1.Rmd",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}